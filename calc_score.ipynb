{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_loss(baseline_acc, current_acc):\n",
    "    \"\"\"Calculate normalized performance loss.\"\"\"\n",
    "    return (baseline_acc - current_acc) / baseline_acc if baseline_acc != 0 else 0\n",
    "\n",
    "def calculate_differential_losses(pruning_results, baseline):\n",
    "    \"\"\"\n",
    "    Calculate the differential of performance losses across pruning ratios.\n",
    "    Arguments:\n",
    "    pruning_results -- list of tuples, where each tuple contains (pruning_ratio, obj_acc, rel_acc, triplet_acc)\n",
    "    baseline -- tuple of (baseline_obj_acc, baseline_rel_acc, baseline_triplet_acc)\n",
    "    \"\"\"\n",
    "    # Sorting by pruning ratios for accurate differential calculation\n",
    "    sorted_results = sorted(pruning_results, key=lambda x: x[0])\n",
    "    ratios = [x[0] for x in sorted_results]\n",
    "    losses = [[calculate_performance_loss(x[i + 1], baseline[i]) for i in range(3)] for x in sorted_results]\n",
    "    \n",
    "    # Calculating differentials of losses\n",
    "    diffs = np.diff(np.array(losses), axis=0)\n",
    "    diffs = np.vstack([diffs, diffs[-1]])  # Duplicate last differential as an approximation for the last point\n",
    "    return ratios, losses, diffs\n",
    "\n",
    "def calculate_lambda(losses):\n",
    "    \"\"\"Calculate dynamic lambda value based on the range and max differential of losses.\"\"\"\n",
    "    if losses.size == 0:\n",
    "        return np.array([1, 1, 1])  # 임시 기본값을 반환\n",
    "    loss_ranges = np.ptp(losses, axis=0)  # Range of each metric's losses\n",
    "    diffs = np.diff(losses, axis=0)\n",
    "    if diffs.size == 0:\n",
    "        max_diffs = np.array([1, 1, 1])  # 임시 기본값을 반환\n",
    "    else:\n",
    "        max_diffs = np.max(np.abs(diffs), axis=0)  # Max differential of each metric's losses\n",
    "    lambda_values = loss_ranges / max_diffs  # Calculate lambda for each metric\n",
    "    return lambda_values\n",
    "\n",
    "\n",
    "def calculate_model_score(losses, diffs, weights=(1, 1, 5), scaling_factor=5.0, mu=0.1, pruning_ratio=0):\n",
    "    \"\"\"Calculate scores incorporating the absolute values of losses and their differentials, adjusted by lambda.\"\"\"\n",
    "    lambda_values = calculate_lambda(np.array([losses])) * scaling_factor  # Convert losses to array and apply scaling factor\n",
    "    adjusted_losses = np.abs(losses)\n",
    "    adjusted_diffs = np.abs(diffs)\n",
    "    \n",
    "    # Calculate score by combining losses, diffs, and the pruning ratio impact\n",
    "    score = sum(weights[i] * (adjusted_losses[i] - lambda_values[i] * adjusted_diffs[i]) for i in range(3)) + mu * pruning_ratio\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sgpn_pruning_results = [\n",
    "    (0.75, 29.989, 79.029, 76.868),\n",
    "    (0.55, 22.592, 77.589, 75.373),\n",
    "    (0.6, 24.510, 78.692, 76.251),\n",
    "    (0.3, 42.276, 81.235, 83.209),\n",
    "    (0.7, 30.074, 78.650, 76.759),\n",
    "    (0.35, 38.377, 81.069, 81.855),\n",
    "    (0.2, 46.491, 82.212, 84.951),\n",
    "    (0.25, 45.817, 81.486, 84.443),\n",
    "    (0.1, 48.957, 82.641, 85.769),\n",
    "    (0.4, 30.285, 78.940, 79.357),\n",
    "    (0.15, 47.524, 82.594, 85.095),\n",
    "    (0.05, 49.989, 82.500, 85.943),\n",
    "    (0.65, 31.191, 79.042, 78.219),\n",
    "    (0.5, 33.867, 77.175, 77.054),\n",
    "    (0.45, 33.783, 78.675, 79.545)\n",
    "]\n",
    "# SGPN 모델의 Baseline 성능\n",
    "sgpn_baseline = (50.158, 82.324, 85.980)\n",
    "\n",
    "# SGFN 모델의 unstructured pruning 결과\n",
    "sgfn_pruning_results = [\n",
    "   (0.65, 49.631, 89.071, 87.256),\n",
    "    (0.75, 43.267, 87.398, 84.398),\n",
    "    (0.45, 51.949, 89.807, 88.417),\n",
    "    (0.5, 51.823, 89.681, 88.208),\n",
    "    (0.35, 52.055, 89.879, 88.528),\n",
    "    (0.3, 52.308, 89.998, 88.506),\n",
    "    (0.25, 52.624, 89.986, 88.491),\n",
    "    (0.6, 50.896, 89.267, 87.631),\n",
    "    (0.05, 52.476, 89.956, 88.508),\n",
    "    (0.7, 46.575, 88.337, 85.920),\n",
    "    (0.1, 52.476, 89.946, 88.516),\n",
    "    (0.4, 51.970, 89.874, 88.508),\n",
    "    (0.15, 52.497, 89.973, 88.508),\n",
    "    (0.2, 52.518, 89.906, 88.513),\n",
    "    (0.55, 51.149, 89.525, 87.928)\n",
    "]\n",
    "\n",
    "# SGFN 모델의 Baseline 성능\n",
    "sgfn_baseline = (52.476, 89.968, 88.486)\n",
    "\n",
    "# Attn + SGFN 모델의 unstructured pruning 결과\n",
    "attn_sgfn_pruning_results = [\n",
    "    (0.2, 54.499, 88.620, 89.066),\n",
    "    (0.45, 51.886, 88.322, 88.030),\n",
    "    (0.6, 45.838, 88.412, 85.464),\n",
    "    (0.55, 49.463, 88.196, 87.147),\n",
    "    (0.5, 50.664, 88.186, 87.576),\n",
    "    (0.7, 43.077, 87.576, 84.755),\n",
    "    (0.15, 54.626, 88.632, 89.106),\n",
    "    (0.4, 52.750, 88.498, 88.417),\n",
    "    (0.35, 53.678, 88.707, 88.655),\n",
    "    (0.75, 36.164, 86.476, 81.444),\n",
    "    (0.3, 53.656, 88.548, 88.689),\n",
    "    (0.05, 54.478, 88.764, 89.187),\n",
    "    (0.25, 54.542, 88.751, 88.979),\n",
    "    (0.1, 54.457, 88.677, 89.195),\n",
    "    (0.65, 43.498, 87.435, 84.921)\n",
    "]\n",
    "\n",
    "# Attn + SGFN 모델의 Baseline 성능\n",
    "attn_sgfn_baseline = (54.499, 88.734, 89.180)\n",
    "\n",
    "# VLSAT 모델의 unstructured pruning 결과\n",
    "vlsat_pruning_results = [\n",
    "    (0.5, 54.394, 88.565, 88.843),\n",
    "    (0.65, 51.570, 88.959, 87.879),\n",
    "    (0.4, 54.689, 88.776, 89.123),\n",
    "    (0.3, 54.689, 89.078, 89.215),\n",
    "    (0.15, 54.773, 88.778, 89.247),\n",
    "    (0.35, 54.605, 89.006, 89.277),\n",
    "    (0.75, 46.175, 87.631, 84.931),\n",
    "    (0.25, 54.689, 88.746, 89.259),\n",
    "    (0.1, 54.773, 88.788, 89.314),\n",
    "    (0.55, 53.846, 88.739, 88.471),\n",
    "    (0.45, 54.858, 88.816, 88.984),\n",
    "    (0.05, 54.731, 88.751, 89.344),\n",
    "    (0.2, 55.047, 88.761, 89.304),\n",
    "    (0.7, 47.334, 88.094, 85.801),\n",
    "    (0.6, 53.256, 88.756, 88.236)\n",
    "]\n",
    "\n",
    "# VLSAT 모델의 Baseline 성능\n",
    "vlsat_baseline = (54.837, 88.766, 89.336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = {\n",
    "    \"SGPN\": {\n",
    "        \"baseline\": sgpn_baseline,\n",
    "        \"pruning_results\": sgpn_pruning_results\n",
    "    },\n",
    "    \"SGFN\": {\n",
    "        \"baseline\": sgfn_baseline,\n",
    "        \"pruning_results\": sgfn_pruning_results\n",
    "    },\n",
    "    \"Attn + SGFN\": {\n",
    "        \"baseline\": attn_sgfn_baseline,\n",
    "        \"pruning_results\": attn_sgfn_pruning_results\n",
    "    },\n",
    "    \"VLSAT\": {\n",
    "        \"baseline\": vlsat_baseline,\n",
    "        \"pruning_results\": vlsat_pruning_results\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(models_data, weights=(1, 2, 5), scaling_factor=3.0, mu=5):\n",
    "    results = {}\n",
    "    for model_name, data in models_data.items():\n",
    "        baseline = data[\"baseline\"]\n",
    "        pruning_results = data[\"pruning_results\"]\n",
    "        if not pruning_results or len(pruning_results) < 2:\n",
    "            print(f\"Not enough data to calculate scores for {model_name}.\")\n",
    "            continue\n",
    "        ratios, losses, diffs = calculate_differential_losses(pruning_results, baseline)\n",
    "        \n",
    "        scores = [calculate_model_score(losses[idx], diffs[idx], weights, scaling_factor, mu, ratios[idx])\n",
    "                  for idx in range(len(ratios))]\n",
    "        \n",
    "        max_score_index = np.argmax(scores)\n",
    "        best_ratio = ratios[max_score_index]\n",
    "        best_score = scores[max_score_index]\n",
    "\n",
    "        results[model_name] = {\n",
    "            \"best_ratio\": best_ratio,\n",
    "            \"best_score\": best_score,\n",
    "            \"all_scores\": scores\n",
    "        }\n",
    "\n",
    "        print(f\"Scores for {model_name}:\")\n",
    "        for ratio, score in zip(ratios, scores):\n",
    "            print(f\"  Pruning Ratio {ratio}, Score: {score:.3f}\")\n",
    "        print(f\"Best Pruning Ratio: {best_ratio}, Highest Score: {best_score:.3f}\\n\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for SGPN:\n",
      "  Pruning Ratio 0.05, Score: 0.015\n",
      "  Pruning Ratio 0.1, Score: 0.055\n",
      "  Pruning Ratio 0.15, Score: 0.129\n",
      "  Pruning Ratio 0.2, Score: 0.162\n",
      "  Pruning Ratio 0.25, Score: 0.231\n",
      "  Pruning Ratio 0.3, Score: 0.410\n",
      "  Pruning Ratio 0.35, Score: 0.625\n",
      "  Pruning Ratio 0.4, Score: 1.199\n",
      "  Pruning Ratio 0.45, Score: 1.027\n",
      "  Pruning Ratio 0.5, Score: 1.244\n",
      "  Pruning Ratio 0.55, Score: 2.101\n",
      "  Pruning Ratio 0.6, Score: 1.837\n",
      "  Pruning Ratio 0.65, Score: 1.252\n",
      "  Pruning Ratio 0.7, Score: 1.432\n",
      "  Pruning Ratio 0.75, Score: 1.424\n",
      "Best Pruning Ratio: 0.55, Highest Score: 2.101\n",
      "\n",
      "Scores for SGFN:\n",
      "  Pruning Ratio 0.05, Score: 0.007\n",
      "  Pruning Ratio 0.1, Score: 0.012\n",
      "  Pruning Ratio 0.15, Score: 0.017\n",
      "  Pruning Ratio 0.2, Score: 0.024\n",
      "  Pruning Ratio 0.25, Score: 0.028\n",
      "  Pruning Ratio 0.3, Score: 0.035\n",
      "  Pruning Ratio 0.35, Score: 0.047\n",
      "  Pruning Ratio 0.4, Score: 0.053\n",
      "  Pruning Ratio 0.45, Score: 0.063\n",
      "  Pruning Ratio 0.5, Score: 0.085\n",
      "  Pruning Ratio 0.55, Score: 0.123\n",
      "  Pruning Ratio 0.6, Score: 0.156\n",
      "  Pruning Ratio 0.65, Score: 0.213\n",
      "  Pruning Ratio 0.7, Score: 0.383\n",
      "  Pruning Ratio 0.75, Score: 0.589\n",
      "Best Pruning Ratio: 0.75, Highest Score: 0.589\n",
      "\n",
      "Scores for Attn + SGFN:\n",
      "  Pruning Ratio 0.05, Score: 0.006\n",
      "  Pruning Ratio 0.1, Score: 0.013\n",
      "  Pruning Ratio 0.15, Score: 0.024\n",
      "  Pruning Ratio 0.2, Score: 0.029\n",
      "  Pruning Ratio 0.25, Score: 0.037\n",
      "  Pruning Ratio 0.3, Score: 0.078\n",
      "  Pruning Ratio 0.35, Score: 0.081\n",
      "  Pruning Ratio 0.4, Score: 0.122\n",
      "  Pruning Ratio 0.45, Score: 0.170\n",
      "  Pruning Ratio 0.5, Score: 0.230\n",
      "  Pruning Ratio 0.55, Score: 0.286\n",
      "  Pruning Ratio 0.6, Score: 0.474\n",
      "  Pruning Ratio 0.65, Score: 0.598\n",
      "  Pruning Ratio 0.7, Score: 0.623\n",
      "  Pruning Ratio 0.75, Score: 1.109\n",
      "Best Pruning Ratio: 0.75, Highest Score: 1.109\n",
      "\n",
      "Scores for VLSAT:\n",
      "  Pruning Ratio 0.05, Score: 0.008\n",
      "  Pruning Ratio 0.1, Score: 0.013\n",
      "  Pruning Ratio 0.15, Score: 0.021\n",
      "  Pruning Ratio 0.2, Score: 0.026\n",
      "  Pruning Ratio 0.25, Score: 0.032\n",
      "  Pruning Ratio 0.3, Score: 0.046\n",
      "  Pruning Ratio 0.35, Score: 0.048\n",
      "  Pruning Ratio 0.4, Score: 0.055\n",
      "  Pruning Ratio 0.45, Score: 0.066\n",
      "  Pruning Ratio 0.5, Score: 0.090\n",
      "  Pruning Ratio 0.55, Score: 0.123\n",
      "  Pruning Ratio 0.6, Score: 0.152\n",
      "  Pruning Ratio 0.65, Score: 0.216\n",
      "  Pruning Ratio 0.7, Score: 0.450\n",
      "  Pruning Ratio 0.75, Score: 0.548\n",
      "Best Pruning Ratio: 0.75, Highest Score: 0.548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results = display_scores(models_data)\n",
    "#final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlsat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
