{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_loss(baseline_acc, current_acc):\n",
    "    \"\"\"Calculate normalized performance loss.\"\"\"\n",
    "    #print('check: baseline_acc: ', baseline_acc, 'current_acc: ', current_acc)\n",
    "    return (current_acc - baseline_acc) / baseline_acc if baseline_acc != 0 else 0\n",
    "\n",
    "def calculate_differential_losses(pruning_results, baseline):\n",
    "    \"\"\"\n",
    "    Calculate the differential of performance losses across pruning ratios.\n",
    "    Arguments:\n",
    "    pruning_results -- list of tuples, where each tuple contains (pruning_ratio, obj_acc, rel_acc, triplet_acc)\n",
    "    baseline -- tuple of (baseline_obj_acc, baseline_rel_acc, baseline_triplet_acc)\n",
    "    \"\"\"\n",
    "    # Sorting by pruning ratios for accurate differential calculation\n",
    "    sorted_results = sorted(pruning_results, key=lambda x: x[0])\n",
    "    ratios = [x[0] for x in sorted_results]\n",
    "    losses = [[calculate_performance_loss(baseline[i], x[i + 1]) for i in range(3)] for x in sorted_results]\n",
    "    \n",
    "    # Calculating differentials of losses\n",
    "    diffs = -np.diff(np.array(losses), axis=0)\n",
    "    diffs = np.vstack([diffs, diffs[-1]])  # Duplicate last differential as an approximation for the last point\n",
    "    return ratios, losses, diffs\n",
    "\n",
    "def calculate_model_score(losses, diffs, weights=(1, 1, 5), mu=5, pruning_ratio=0, detailed=False):\n",
    "    \"\"\"Calculate scores incorporating the absolute values of losses and their differentials, adjusted by lambda.\"\"\"\n",
    "    adjusted_losses = losses\n",
    "    adjusted_diffs = diffs\n",
    "    #print(f'pruning ratio: {pruning_ratio}, adjusted losses: {adjusted_losses}, adjusted diffs: {adjusted_diffs}')\n",
    "    weighted_diff_loss = sum(weights[i] * (adjusted_diffs[i] + adjusted_losses[i]) for i in range(3))\n",
    "    score = weighted_diff_loss + mu * pruning_ratio\n",
    "    \n",
    "    if detailed:\n",
    "        return score, weighted_diff_loss\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_loss(pruning_results, baseline):\n",
    "    losses = np.array([\n",
    "        [calculate_performance_loss(baseline[i], x[i + 1]) for i in range(3)]\n",
    "        for x in pruning_results\n",
    "    ])\n",
    "    average_losses = np.mean(np.abs(losses), axis=0)\n",
    "    return average_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGFN Pruning Results: [(0.0, 52.39, 92.14, 89.19), (0.05, 52.39, 92.14, 89.19), (0.1, 52.39, 92.07, 89.18), (0.15, 52.39, 91.79, 89.09), (0.2, 52.39, 90.99, 88.87), (0.25, 52.39, 90.39, 88.66), (0.3, 52.46, 89.63, 88.36), (0.35, 52.46, 88.57, 88.13), (0.4, 52.46, 89.17, 87.92), (0.45, 52.27, 85.12, 87.1), (0.5, 52.27, 83.41, 86.65), (0.55, 52.41, 85.73, 86.51), (0.6, 48.6, 67.92, 84.27), (0.65, 41.85, 67.92, 81.56), (0.7, 32.5, 67.92, 76.68), (0.75, 28.47, 67.92, 74.99)]\n",
      "SGFN Baseline: (52.39, 92.14, 89.19)\n",
      "Attention SGFN Pruning Results: [(0.0, 54.6259220231823, 90.18144861434732, 89.50473451985523), (0.05, 54.478398314014754, 88.98170641019286, 89.40062465916415), (0.1, 54.373024236037935, 85.12220514600169, 89.20727777502354), (0.15, 54.3940990516333, 81.01234445491052, 89.00897327846909), (0.2, 54.58377239199157, 73.1247831044569, 88.68672847156809), (0.25, 54.58377239199157, 70.74760795201031, 88.5256060681176), (0.3, 54.64699683877766, 74.58727876654604, 88.30994992811462), (0.35, 54.604847207586936, 74.50299935551038, 87.88359526052253), (0.4, 54.836670179135936, 76.17619354518864, 86.98130980119974), (0.45, 53.50895679662803, 72.93639383273016, 86.36656586188091), (0.5, 49.82086406743941, 73.10247384859451, 85.18913291358882), (0.55, 45.39515279241306, 73.86594616032919, 83.12180853700858), (0.6, 39.852476290832456, 74.26751276585196, 80.50171037628279), (0.65, 33.88830347734457, 71.44167368995092, 78.58063556591145), (0.7, 30.389884088514226, 73.96014079619255, 77.21977095830648), (0.75, 27.544783983140142, 76.79589509692133, 76.68434881760943)]\n",
      "Attention SGFN Baseline: (54.6259220231823, 90.18144861434732, 89.50473451985523)\n",
      "SGPN Pruning Results: [(0.0, 51.338, 83.018, 86.999), (0.05, 44.995, 82.239, 83.394), (0.1, 38.651, 80.494, 81.825), (0.15, 39.347, 79.773, 80.817), (0.2, 39.536, 75.353, 78.707), (0.25, 32.982, 76.023, 76.655), (0.3, 35.174, 76.974, 77.75), (0.35, 33.93, 78.977, 78.486), (0.4, 33.214, 69.692, 77.247), (0.45, 31.97, 78.484, 76.952), (0.5, 30.748, 78.479, 76.89), (0.55, 30.285, 77.307, 76.459), (0.6, 29.547, 76.843, 74.934), (0.65, 28.683, 76.776, 74.562), (0.7, 27.819, 77.507, 75.14), (0.75, 28.219, 79.153, 75.346)]\n",
      "SGPN Baseline: (51.338, 83.018, 86.999)\n",
      "VLSAT Pruning Results: [(0.0, 51.338, 83.018, 86.999), (0.05, 44.995, 82.239, 83.394), (0.1, 38.651, 80.494, 81.825), (0.15, 39.347, 79.773, 80.817), (0.2, 39.536, 75.353, 78.707), (0.25, 32.982, 76.023, 76.655), (0.3, 35.174, 76.974, 77.75), (0.35, 33.93, 78.977, 78.486), (0.4, 33.214, 69.692, 77.247), (0.45, 31.97, 78.484, 76.952), (0.5, 30.748, 78.479, 76.89), (0.55, 30.285, 77.307, 76.459), (0.6, 29.547, 76.843, 74.934), (0.65, 28.683, 76.776, 74.562), (0.7, 27.819, 77.507, 75.14), (0.75, 28.219, 79.153, 75.346)]\n",
      "VLSAT Baseline: (51.338, 83.018, 86.999)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir = '/home/oi/Desktop/song/lightweight_3DSSG/visualization/pruning_infer_data/'\n",
    "# CSV 파일 경로\n",
    "# file_path1 = base_dir + 'sgfn_baseline_unst_results.csv'\n",
    "# file_path2 = base_dir +'attn_sgfn_baseline_unst_results.csv'\n",
    "# file_path3 = base_dir +'sgpn_baseline_unst_results.csv'\n",
    "# file_paht4 = base_dir + 'vlsat_baseline_unst_results.csv'\n",
    "\n",
    "# file_path1 = base_dir + 'sgfn_baseline_st_results.csv'\n",
    "# file_path2 = base_dir +'attn_sgfn_baseline_st_results.csv'\n",
    "# file_path3 = base_dir +'sgpn_baseline_st_results.csv'\n",
    "# file_paht4 = base_dir + 'vlsat_baseline_st_results.csv'\n",
    "\n",
    "file_path1 = base_dir + 'SGFN_param60_Structured_Pruning_Results.csv'\n",
    "file_path2 = base_dir +'Attn+SGFN_param60_Structured_Pruning_Results.csv'\n",
    "file_path3 = base_dir +'SGPN_param40_Structured_Pruning_results.csv'\n",
    "file_paht4 = base_dir + 'SGPN_param40_Structured_Pruning_results.csv'\n",
    "\n",
    "# CSV 파일 로드\n",
    "df1 = pd.read_csv(file_path1).sort_values(by='Pruning Ratio')\n",
    "df2 = pd.read_csv(file_path2).sort_values(by='Pruning Ratio')\n",
    "df3 = pd.read_csv(file_path3).sort_values(by='Pruning Ratio')\n",
    "df4 = pd.read_csv(file_paht4).sort_values(by='Pruning Ratio')\n",
    "\n",
    "\n",
    "# 필요한 데이터를 추출하여 리스트로 변환\n",
    "sgfn_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df1.iterrows()\n",
    "]\n",
    "sgfn_baseline = (\n",
    "    df1['3d obj Acc@1'].iloc[0],\n",
    "    df1['3d rel Acc@1'].iloc[0],\n",
    "    df1['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "attn_sgfn_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df2.iterrows()\n",
    "]\n",
    "attn_sgfn_baseline = (\n",
    "    df2['3d obj Acc@1'].iloc[0],\n",
    "    df2['3d rel Acc@1'].iloc[0],\n",
    "    df2['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "\n",
    "sgpn_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df3.iterrows()\n",
    "]\n",
    "sgpn_baseline = (\n",
    "    df3['3d obj Acc@1'].iloc[0],\n",
    "    df3['3d rel Acc@1'].iloc[0],\n",
    "    df3['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "\n",
    "vlsat_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df4.iterrows()\n",
    "]\n",
    "vlsat_baseline = (\n",
    "    df4['3d obj Acc@1'].iloc[0],\n",
    "    df4['3d rel Acc@1'].iloc[0],\n",
    "    df4['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "print(\"SGFN Pruning Results:\", sgfn_pruning_results)\n",
    "print(\"SGFN Baseline:\", sgfn_baseline)\n",
    "print(\"Attention SGFN Pruning Results:\", attn_sgfn_pruning_results)\n",
    "print(\"Attention SGFN Baseline:\", attn_sgfn_baseline)\n",
    "print(\"SGPN Pruning Results:\", sgpn_pruning_results)\n",
    "print(\"SGPN Baseline:\", sgpn_baseline)\n",
    "print(\"VLSAT Pruning Results:\", vlsat_pruning_results)\n",
    "print(\"VLSAT Baseline:\", vlsat_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = {\n",
    "    \"SGPN\": {\n",
    "        \"baseline\": sgpn_baseline,\n",
    "        \"pruning_results\": sgpn_pruning_results\n",
    "    },\n",
    "    \"SGFN\": {\n",
    "        \"baseline\": sgfn_baseline,\n",
    "        \"pruning_results\": sgfn_pruning_results\n",
    "    },\n",
    "    \"Attn + SGFN\": {\n",
    "        \"baseline\": attn_sgfn_baseline,\n",
    "        \"pruning_results\": attn_sgfn_pruning_results\n",
    "    },\n",
    "    \"VLSAT\": {\n",
    "        \"baseline\": vlsat_baseline,\n",
    "        \"pruning_results\": vlsat_pruning_results\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for SGPN:\n",
      "Calculated Weights: [0.1053903  0.55615523 0.33845447]\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.032264673400253366, Weighted Ratio: 0.000, Total Score: 0.032\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: -0.001447211416996999, Weighted Ratio: 0.010, Total Score: 0.009\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: -0.05575935283365316, Weighted Ratio: 0.020, Total Score: -0.036\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: -0.03297380305576174, Weighted Ratio: 0.030, Total Score: -0.003\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.0908870388970662, Weighted Ratio: 0.040, Total Score: -0.051\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.1399157783979515, Weighted Ratio: 0.050, Total Score: -0.090\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.123382306116936, Weighted Ratio: 0.060, Total Score: -0.063\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.027434085296334104, Weighted Ratio: 0.070, Total Score: 0.043\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: -0.2196164620752432, Weighted Ratio: 0.080, Total Score: -0.140\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.1064370384677463, Weighted Ratio: 0.090, Total Score: -0.016\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.10152496108008388, Weighted Ratio: 0.100, Total Score: -0.002\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: -0.11192613444467789, Weighted Ratio: 0.110, Total Score: -0.002\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.12936880658111014, Weighted Ratio: 0.120, Total Score: -0.009\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.14208031708502733, Weighted Ratio: 0.130, Total Score: -0.012\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.14398567233098455, Weighted Ratio: 0.140, Total Score: -0.004\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.13133621276913393, Weighted Ratio: 0.150, Total Score: 0.019\n",
      "Best Pruning Ratio: 0.35, Highest Score: 0.043\n",
      "\n",
      "Scores for SGFN:\n",
      "Calculated Weights: [0.26646576 0.2090184  0.52451584]\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.0, Weighted Ratio: 0.000, Total Score: 0.000\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: 0.000217602915305905, Weighted Ratio: 0.010, Total Score: 0.010\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: 0.0009468528301185949, Weighted Ratio: 0.020, Total Score: 0.021\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: 0.001726525006504804, Weighted Ratio: 0.030, Total Score: 0.032\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.0018945649017585186, Weighted Ratio: 0.040, Total Score: 0.038\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.003954438691368724, Weighted Ratio: 0.050, Total Score: 0.046\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.006461801681456951, Weighted Ratio: 0.060, Total Score: 0.054\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.014102307071417313, Weighted Ratio: 0.070, Total Score: 0.056\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: 0.001125980048834828, Weighted Ratio: 0.080, Total Score: 0.081\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.02230065598137207, Weighted Ratio: 0.090, Total Score: 0.068\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.04050330944404787, Weighted Ratio: 0.100, Total Score: 0.059\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: 0.04275329232382911, Weighted Ratio: 0.110, Total Score: 0.153\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.05288436920838331, Weighted Ratio: 0.120, Total Score: 0.067\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.0771677548235567, Weighted Ratio: 0.130, Total Score: 0.053\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.19924095156781335, Weighted Ratio: 0.140, Total Score: -0.059\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.22967700771220717, Weighted Ratio: 0.150, Total Score: -0.080\n",
      "Best Pruning Ratio: 0.55, Highest Score: 0.153\n",
      "\n",
      "Scores for Attn + SGFN:\n",
      "Calculated Weights: [0.23133873 0.1853794  0.58328186]\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.0037694397325174467, Weighted Ratio: 0.000, Total Score: 0.004\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: 0.005870507137342686, Weighted Ratio: 0.010, Total Score: 0.016\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: -0.0037579928880660815, Weighted Ratio: 0.020, Total Score: 0.016\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: -0.00555016170864487, Weighted Ratio: 0.030, Total Score: 0.024\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.03463481616614474, Weighted Ratio: 0.040, Total Score: 0.005\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.05326328336573591, Weighted Ratio: 0.050, Total Score: -0.003\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.036622475113480074, Weighted Ratio: 0.060, Total Score: 0.023\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.04142412152181658, Weighted Ratio: 0.070, Total Score: 0.029\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: -0.02805286719979795, Weighted Ratio: 0.080, Total Score: 0.052\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.037679832325603624, Weighted Ratio: 0.090, Total Score: 0.052\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.05293543929824581, Weighted Ratio: 0.100, Total Score: 0.047\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: -0.07450447713302517, Weighted Ratio: 0.110, Total Score: 0.035\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.11036262574637301, Weighted Ratio: 0.120, Total Score: 0.010\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.17902778346098602, Weighted Ratio: 0.130, Total Score: -0.049\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.20633309948475348, Weighted Ratio: 0.140, Total Score: -0.066\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.2160419628356801, Weighted Ratio: 0.150, Total Score: -0.066\n",
      "Best Pruning Ratio: 0.45, Highest Score: 0.052\n",
      "\n",
      "Scores for VLSAT:\n",
      "Calculated Weights: [0.1053903  0.55615523 0.33845447]\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.032264673400253366, Weighted Ratio: 0.000, Total Score: 0.032\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: -0.001447211416996999, Weighted Ratio: 0.010, Total Score: 0.009\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: -0.05575935283365316, Weighted Ratio: 0.020, Total Score: -0.036\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: -0.03297380305576174, Weighted Ratio: 0.030, Total Score: -0.003\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.0908870388970662, Weighted Ratio: 0.040, Total Score: -0.051\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.1399157783979515, Weighted Ratio: 0.050, Total Score: -0.090\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.123382306116936, Weighted Ratio: 0.060, Total Score: -0.063\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.027434085296334104, Weighted Ratio: 0.070, Total Score: 0.043\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: -0.2196164620752432, Weighted Ratio: 0.080, Total Score: -0.140\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.1064370384677463, Weighted Ratio: 0.090, Total Score: -0.016\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.10152496108008388, Weighted Ratio: 0.100, Total Score: -0.002\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: -0.11192613444467789, Weighted Ratio: 0.110, Total Score: -0.002\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.12936880658111014, Weighted Ratio: 0.120, Total Score: -0.009\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.14208031708502733, Weighted Ratio: 0.130, Total Score: -0.012\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.14398567233098455, Weighted Ratio: 0.140, Total Score: -0.004\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.13133621276913393, Weighted Ratio: 0.150, Total Score: 0.019\n",
      "Best Pruning Ratio: 0.35, Highest Score: 0.043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_scores_limited_ratio(models_data, base_weights=(1, 1, 1), mu=0.2, max_ratio=0.7):\n",
    "    results = {}\n",
    "    for model_name, data in models_data.items():\n",
    "        baseline = data[\"baseline\"]\n",
    "        pruning_results = data[\"pruning_results\"]\n",
    "        \n",
    "        # Pruning ratio 0.7 이하로 필터링\n",
    "        pruning_results = [result for result in pruning_results if result[0] <= max_ratio]\n",
    "        \n",
    "        if not pruning_results or len(pruning_results) < 2:\n",
    "            print(f\"Not enough data to calculate scores for {model_name}.\")\n",
    "            continue\n",
    "        \n",
    "        # 가중치 계산 (자동 계산된 가중치 * 임의의 가중치)\n",
    "        average_losses = calculate_average_loss(pruning_results, baseline)\n",
    "        auto_weights = 1 / average_losses\n",
    "        auto_weights = auto_weights / np.sum(auto_weights)  # 가중치 정규화\n",
    "        \n",
    "        # 임의의 가중치와 자동 계산된 가중치를 곱함\n",
    "        final_weights = auto_weights * np.array(base_weights)\n",
    "        final_weights = final_weights / np.sum(final_weights)  # 최종 가중치 정규화\n",
    "        \n",
    "        ratios, losses, diffs = calculate_differential_losses(pruning_results, baseline)\n",
    "        \n",
    "        # Store detailed score components for each pruning ratio\n",
    "        detailed_scores = []\n",
    "        scores = []\n",
    "        for idx in range(len(ratios)):\n",
    "            score, components = calculate_model_score(losses[idx], diffs[idx], final_weights, mu, ratios[idx], detailed=True)\n",
    "            scores.append(score)\n",
    "            detailed_scores.append({\n",
    "                \"ratio\": ratios[idx],\n",
    "                \"weighted_diff_loss\": components,\n",
    "                \"weighted_ratio\": mu * ratios[idx],\n",
    "                \"total_score\": score\n",
    "            })\n",
    "        \n",
    "        max_score_index = np.argmax(scores)\n",
    "        best_ratio = ratios[max_score_index]\n",
    "        best_score = scores[max_score_index]\n",
    "\n",
    "        results[model_name] = {\n",
    "            \"best_ratio\": best_ratio,\n",
    "            \"best_score\": best_score,\n",
    "            \"all_scores\": scores,\n",
    "            \"detailed_scores\": detailed_scores\n",
    "        }\n",
    "\n",
    "        print(f\"Scores for {model_name}:\")\n",
    "        print(f\"Calculated Weights: {final_weights}\")\n",
    "        for entry in detailed_scores:\n",
    "            print(f\"  Pruning Ratio {entry['ratio']}, Weighted Diff-Loss: {entry['weighted_diff_loss']}, \"\n",
    "                  f\"Weighted Ratio: {entry['weighted_ratio']:.3f}, Total Score: {entry['total_score']:.3f}\")\n",
    "        print(f\"Best Pruning Ratio: {best_ratio}, Highest Score: {best_score:.3f}\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# 예제 실행 (max_ratio를 0.7로 설정하여 pruning ratio 0.7 이하의 데이터만 사용)\n",
    "results = display_scores_limited_ratio(models_data, max_ratio=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_loss(baseline_acc, current_acc):\n",
    "    return (current_acc - baseline_acc) / baseline_acc if baseline_acc != 0 else 0\n",
    "\n",
    "def calculate_average_loss(pruning_results, baseline):\n",
    "    losses = np.array([\n",
    "        [calculate_performance_loss(baseline[i], x[i + 1]) for i in range(3)]\n",
    "        for x in pruning_results\n",
    "    ])\n",
    "    average_losses = np.mean(np.abs(losses), axis=0)\n",
    "    return average_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07364298, 0.62573474, 0.30062228])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 성능 지표의 평균 손실 계산\n",
    "average_losses = calculate_average_loss(SGPN_Prune_Results, SGPN_Baseline)\n",
    "\n",
    "# 역수로 가중치 계산\n",
    "weights = 1 / average_losses\n",
    "weights = weights / np.sum(weights)  # 가중치의 합을 1로 정규화\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# SGFN 구조화된 및 비구조화된 프루닝 결과\n",
    "vlsat_structured_data = {\n",
    "    \"Pruning Ratio\": [0.7, 0.55, 0.3, 0.25, 0.2, 0, 0.35, 0.45, 0.05, 0.65, 0.4, 0.1, 0.6, 0.15, 0.5, 0.75],\n",
    "    \"3d obj Acc@1\": [41.581, 53.214, 55.258, 55.385, 55.385, 55.406, 55.216, 55.216, 55.427, 45.922, 55.258, 55.490, 49.905, 55.385, 54.984, 37.450],\n",
    "    \"3d rel Acc@1\": [38.845, 38.845, 65.470, 66.546, 75.195, 91.175, 66.152, 56.646, 87.311, 38.845, 68.807, 84.512, 38.845, 80.078, 49.831, 5.830],\n",
    "    \"3d triplet Acc@50\": [79.280, 85.169, 88.605, 88.712, 88.870, 89.701, 88.387, 87.965, 89.329, 81.791, 88.070, 89.187, 84.094, 89.068, 87.227, 77.621]\n",
    "}\n",
    "\n",
    "unstructured_data = {\n",
    "    \"Pruning Ratio\": [0.8, 0.65, 0.85, 0.75, 0.45, 0.5, 0.35, 0.3, 0.25, 0.6, 0.05, 0.7, 0.1, 0.4, 0.9, 0.15, 0.95, 0.2, 0.55],\n",
    "    \"3d obj Acc@1\": [38.609, 49.631, 32.455, 43.267, 51.949, 51.823, 52.055, 52.308, 52.624, 50.896, 52.476, 46.575, 52.476, 51.970, 23.878, 52.497, 4.067, 52.518, 51.149],\n",
    "    \"3d rel Acc@1\": [85.145, 89.071, 79.773, 87.398, 89.807, 89.681, 89.879, 89.998, 89.986, 89.267, 89.956, 88.337, 89.946, 89.874, 53.827, 89.973, 13.326, 89.906, 89.525],\n",
    "    \"3d triplet Acc@50\": [82.103, 87.256, 77.862, 84.398, 88.417, 88.208, 88.528, 88.506, 88.491, 87.631, 88.508, 85.920, 88.516, 88.508, 73.616, 88.508, 72.639, 88.513, 87.928]\n",
    "}\n",
    "# DataFrame 생성 및 정렬\n",
    "df_structured = pd.DataFrame(vlsat_structured_data).sort_values('Pruning Ratio').round(2)\n",
    "#df_unstructured = pd.DataFrame(unstructured_data).sort_values('Pruning Ratio').round(2)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df_structured.to_csv('VLSAT_param65_Structured_pruninig_results.csv', index=False)\n",
    "#df_unstructured.to_csv('sgfn_baseline_unst_results.csv', index=False)\n",
    "\n",
    "print(\"CSV 파일이 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlsat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
