{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_loss(baseline_acc, current_acc):\n",
    "    \"\"\"Calculate normalized performance loss.\"\"\"\n",
    "    #print('check: baseline_acc: ', baseline_acc, 'current_acc: ', current_acc)\n",
    "    return (current_acc - baseline_acc) / baseline_acc if baseline_acc != 0 else 0\n",
    "\n",
    "def calculate_differential_losses(pruning_results, baseline):\n",
    "    \"\"\"\n",
    "    Calculate the differential of performance losses across pruning ratios.\n",
    "    Arguments:\n",
    "    pruning_results -- list of tuples, where each tuple contains (pruning_ratio, obj_acc, rel_acc, triplet_acc)\n",
    "    baseline -- tuple of (baseline_obj_acc, baseline_rel_acc, baseline_triplet_acc)\n",
    "    \"\"\"\n",
    "    # Sorting by pruning ratios for accurate differential calculation\n",
    "    sorted_results = sorted(pruning_results, key=lambda x: x[0])\n",
    "    ratios = [x[0] for x in sorted_results]\n",
    "    losses = [[calculate_performance_loss(baseline[i], x[i + 1]) for i in range(3)] for x in sorted_results]\n",
    "    \n",
    "    # Calculating differentials of losses\n",
    "    diffs = -np.diff(np.array(losses), axis=0)\n",
    "    diffs = np.vstack([diffs, diffs[-1]])  # Duplicate last differential as an approximation for the last point\n",
    "    return ratios, losses, diffs\n",
    "\n",
    "def calculate_model_score(losses, diffs, weights=(1, 1, 5), mu=5, pruning_ratio=0, detailed=False):\n",
    "    \"\"\"Calculate scores incorporating the absolute values of losses and their differentials, adjusted by lambda.\"\"\"\n",
    "    adjusted_losses = losses\n",
    "    adjusted_diffs = diffs\n",
    "    #print(f'pruning ratio: {pruning_ratio}, adjusted losses: {adjusted_losses}, adjusted diffs: {adjusted_diffs}')\n",
    "    weighted_diff_loss = sum(weights[i] * (adjusted_diffs[i] + adjusted_losses[i]) for i in range(3))\n",
    "    score = weighted_diff_loss + mu * pruning_ratio\n",
    "    \n",
    "    if detailed:\n",
    "        return score, weighted_diff_loss\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGFN Pruning Results: [(0.0, 52.39, 92.14, 89.19), (0.05, 52.39, 92.14, 89.19), (0.1, 52.39, 92.07, 89.18), (0.15, 52.39, 91.79, 89.09), (0.2, 52.39, 90.99, 88.87), (0.25, 52.39, 90.39, 88.66), (0.3, 52.46, 89.63, 88.36), (0.35, 52.46, 88.57, 88.13), (0.4, 52.46, 89.17, 87.92), (0.45, 52.27, 85.12, 87.1), (0.5, 52.27, 83.41, 86.65), (0.55, 52.41, 85.73, 86.51), (0.6, 48.6, 67.92, 84.27), (0.65, 41.85, 67.92, 81.56), (0.7, 32.5, 67.92, 76.68), (0.75, 28.47, 67.92, 74.99)]\n",
      "SGFN Baseline: (52.39, 92.14, 89.19)\n",
      "Attention SGFN Pruning Results: [(0.0, 54.6259220231823, 90.18144861434732, 89.50473451985523), (0.05, 54.478398314014754, 88.98170641019286, 89.40062465916415), (0.1, 54.373024236037935, 85.12220514600169, 89.20727777502354), (0.15, 54.3940990516333, 81.01234445491052, 89.00897327846909), (0.2, 54.58377239199157, 73.1247831044569, 88.68672847156809), (0.25, 54.58377239199157, 70.74760795201031, 88.5256060681176), (0.3, 54.64699683877766, 74.58727876654604, 88.30994992811462), (0.35, 54.604847207586936, 74.50299935551038, 87.88359526052253), (0.4, 54.836670179135936, 76.17619354518864, 86.98130980119974), (0.45, 53.50895679662803, 72.93639383273016, 86.36656586188091), (0.5, 49.82086406743941, 73.10247384859451, 85.18913291358882), (0.55, 45.39515279241306, 73.86594616032919, 83.12180853700858), (0.6, 39.852476290832456, 74.26751276585196, 80.50171037628279), (0.65, 33.88830347734457, 71.44167368995092, 78.58063556591145), (0.7, 30.389884088514226, 73.96014079619255, 77.21977095830648), (0.75, 27.544783983140142, 76.79589509692133, 76.68434881760943)]\n",
      "Attention SGFN Baseline: (54.6259220231823, 90.18144861434732, 89.50473451985523)\n",
      "SGPN Pruning Results: [(0.0, 51.338, 83.018, 86.999), (0.05, 44.995, 82.239, 83.394), (0.1, 38.651, 80.494, 81.825), (0.15, 39.347, 79.773, 80.817), (0.2, 39.536, 75.353, 78.707), (0.25, 32.982, 76.023, 76.655), (0.3, 35.174, 76.974, 77.75), (0.35, 33.93, 78.977, 78.486), (0.4, 33.214, 69.692, 77.247), (0.45, 31.97, 78.484, 76.952), (0.5, 30.748, 78.479, 76.89), (0.55, 30.285, 77.307, 76.459), (0.6, 29.547, 76.843, 74.934), (0.65, 28.683, 76.776, 74.562), (0.7, 27.819, 77.507, 75.14), (0.75, 28.219, 79.153, 75.346)]\n",
      "SGPN Baseline: (51.338, 83.018, 86.999)\n",
      "VLSAT Pruning Results: [(0.0, 56.24, 89.8, 89.89), (0.05, 54.73, 87.96, 89.36), (0.1, 54.82, 87.34, 89.43), (0.15, 54.86, 86.37, 89.4), (0.2, 54.82, 85.2, 89.31), (0.25, 54.69, 84.2, 89.2), (0.3, 54.48, 83.23, 89.07), (0.35, 54.04, 81.01, 88.82), (0.4, 53.02, 77.81, 88.54), (0.45, 52.08, 72.8, 87.94), (0.5, 50.6, 54.42, 86.64), (0.55, 49.4, 54.73, 84.05), (0.6, 42.4, 66.38, 81.22), (0.65, 38.46, 67.58, 79.84), (0.7, 33.53, 69.49, 78.13), (0.75, 27.8, 69.92, 75.48), (0.8, 14.6, 77.75, 73.37), (0.85, 12.41, 78.3, 72.43), (0.9, 12.41, 78.3, 72.43), (0.95, 12.41, 78.3, 72.43)]\n",
      "VLSAT Baseline: (56.24, 89.8, 89.89)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir = '/home/song/Desktop/song/lightweight_3DSSG/visualization/pruning_infer_data/'\n",
    "# CSV 파일 경로\n",
    "file_path1 = base_dir + 'sgfn_baseline_st_results.csv'\n",
    "file_path2 = base_dir +'attn_sgfn_baseline_st_results.csv'\n",
    "file_path3 = base_dir +'sgpn_baseline_st_results.csv'\n",
    "file_paht4 = base_dir + 'vlsat_baseline_st_results.csv'\n",
    "# CSV 파일 로드\n",
    "df1 = pd.read_csv(file_path1).sort_values(by='Pruning Ratio')\n",
    "df2 = pd.read_csv(file_path2).sort_values(by='Pruning Ratio')\n",
    "df3 = pd.read_csv(file_path3).sort_values(by='Pruning Ratio')\n",
    "df4 = pd.read_csv(file_paht4).sort_values(by='Pruning Ratio')\n",
    "\n",
    "\n",
    "# 필요한 데이터를 추출하여 리스트로 변환\n",
    "sgfn_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df1.iterrows()\n",
    "]\n",
    "sgfn_baseline = (\n",
    "    df1['3d obj Acc@1'].iloc[0],\n",
    "    df1['3d rel Acc@1'].iloc[0],\n",
    "    df1['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "attn_sgfn_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df2.iterrows()\n",
    "]\n",
    "attn_sgfn_baseline = (\n",
    "    df2['3d obj Acc@1'].iloc[0],\n",
    "    df2['3d rel Acc@1'].iloc[0],\n",
    "    df2['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "\n",
    "sgpn_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df3.iterrows()\n",
    "]\n",
    "sgpn_baseline = (\n",
    "    df3['3d obj Acc@1'].iloc[0],\n",
    "    df3['3d rel Acc@1'].iloc[0],\n",
    "    df3['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "\n",
    "vlsat_pruning_results = [\n",
    "    (row['Pruning Ratio'], row['3d obj Acc@1'], row['3d rel Acc@1'], row['3d triplet Acc@50'])\n",
    "    for index, row in df4.iterrows()\n",
    "]\n",
    "vlsat_baseline = (\n",
    "    df4['3d obj Acc@1'].iloc[0],\n",
    "    df4['3d rel Acc@1'].iloc[0],\n",
    "    df4['3d triplet Acc@50'].iloc[0]\n",
    ")\n",
    "print(\"SGFN Pruning Results:\", sgfn_pruning_results)\n",
    "print(\"SGFN Baseline:\", sgfn_baseline)\n",
    "print(\"Attention SGFN Pruning Results:\", attn_sgfn_pruning_results)\n",
    "print(\"Attention SGFN Baseline:\", attn_sgfn_baseline)\n",
    "print(\"SGPN Pruning Results:\", sgpn_pruning_results)\n",
    "print(\"SGPN Baseline:\", sgpn_baseline)\n",
    "print(\"VLSAT Pruning Results:\", vlsat_pruning_results)\n",
    "print(\"VLSAT Baseline:\", vlsat_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = {\n",
    "    \"SGPN\": {\n",
    "        \"baseline\": sgpn_baseline,\n",
    "        \"pruning_results\": sgpn_pruning_results\n",
    "    },\n",
    "    \"SGFN\": {\n",
    "        \"baseline\": sgfn_baseline,\n",
    "        \"pruning_results\": sgfn_pruning_results\n",
    "    },\n",
    "    \"Attn + SGFN\": {\n",
    "        \"baseline\": attn_sgfn_baseline,\n",
    "        \"pruning_results\": attn_sgfn_pruning_results\n",
    "    },\n",
    "    \"VLSAT\": {\n",
    "        \"baseline\": vlsat_baseline,\n",
    "        \"pruning_results\": vlsat_pruning_results\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(models_data, weights=(0, 0, 5), mu=0.5):\n",
    "    results = {}\n",
    "    for model_name, data in models_data.items():\n",
    "        baseline = data[\"baseline\"]\n",
    "        pruning_results = data[\"pruning_results\"]\n",
    "        if not pruning_results or len(pruning_results) < 2:\n",
    "            print(f\"Not enough data to calculate scores for {model_name}.\")\n",
    "            continue\n",
    "        \n",
    "        ratios, losses, diffs = calculate_differential_losses(pruning_results, baseline)\n",
    "        \n",
    "        # Store detailed score components for each pruning ratio\n",
    "        detailed_scores = []\n",
    "        scores = []\n",
    "        for idx in range(len(ratios)):\n",
    "            score, components = calculate_model_score(losses[idx], diffs[idx], weights, mu, ratios[idx], detailed=True)\n",
    "            scores.append(score)\n",
    "            detailed_scores.append({\n",
    "                \"ratio\": ratios[idx],\n",
    "                \"weighted_diff_loss\": components,\n",
    "                \"weighted_ratio\": mu * ratios[idx],\n",
    "                \"total_score\": score\n",
    "            })\n",
    "        \n",
    "        max_score_index = np.argmax(scores)\n",
    "        best_ratio = ratios[max_score_index]\n",
    "        best_score = scores[max_score_index]\n",
    "\n",
    "        results[model_name] = {\n",
    "            \"best_ratio\": best_ratio,\n",
    "            \"best_score\": best_score,\n",
    "            \"all_scores\": scores,\n",
    "            \"detailed_scores\": detailed_scores\n",
    "        }\n",
    "\n",
    "        print(f\"Scores for {model_name}:\")\n",
    "        for entry in detailed_scores:\n",
    "            print(f\"  Pruning Ratio {entry['ratio']}, Weighted Diff-Loss: {entry['weighted_diff_loss']}, \"\n",
    "                  f\"Weighted Ratio: {entry['weighted_ratio']:.3f}, Total Score: {entry['total_score']:.3f}\")\n",
    "        print(f\"Best Pruning Ratio: {best_ratio}, Highest Score: {best_score:.3f}\\n\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for SGPN:\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.20718628949757986, Weighted Ratio: 0.000, Total Score: 0.207\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: -0.11701283922803639, Weighted Ratio: 0.025, Total Score: -0.092\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: -0.2394280394027508, Weighted Ratio: 0.050, Total Score: -0.189\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: -0.23402567845607436, Weighted Ratio: 0.075, Total Score: -0.159\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.35862481177944633, Weighted Ratio: 0.100, Total Score: -0.259\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.6574213496706854, Weighted Ratio: 0.125, Total Score: -0.532\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.5738571707720779, Weighted Ratio: 0.150, Total Score: -0.424\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.41805078219289804, Weighted Ratio: 0.175, Total Score: -0.243\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: -0.5435119943907398, Weighted Ratio: 0.200, Total Score: -0.344\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.5738571707720779, Weighted Ratio: 0.225, Total Score: -0.349\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.5562132898079286, Weighted Ratio: 0.250, Total Score: -0.306\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: -0.518109403556362, Weighted Ratio: 0.275, Total Score: -0.243\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.6720192186117081, Weighted Ratio: 0.300, Total Score: -0.372\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.7479971034149818, Weighted Ratio: 0.325, Total Score: -0.423\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.6933987746985597, Weighted Ratio: 0.350, Total Score: -0.343\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.6815595581558407, Weighted Ratio: 0.375, Total Score: -0.307\n",
      "Best Pruning Ratio: 0.0, Highest Score: 0.207\n",
      "\n",
      "Scores for SGFN:\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.0, Weighted Ratio: 0.000, Total Score: 0.000\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: 0.0005606009642331487, Weighted Ratio: 0.025, Total Score: 0.026\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: 0.004484807713869969, Weighted Ratio: 0.050, Total Score: 0.054\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: 0.006727211570804158, Weighted Ratio: 0.075, Total Score: 0.082\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.006166610606569414, Weighted Ratio: 0.100, Total Score: 0.094\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.01289382217737437, Weighted Ratio: 0.125, Total Score: 0.112\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.03363605785401919, Weighted Ratio: 0.150, Total Score: 0.116\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.04765108195986145, Weighted Ratio: 0.175, Total Score: 0.127\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: -0.025227043390514004, Weighted Ratio: 0.200, Total Score: 0.175\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.09193855813432081, Weighted Ratio: 0.225, Total Score: 0.133\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.13454423141607758, Weighted Ratio: 0.250, Total Score: 0.115\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: -0.02466644242628005, Weighted Ratio: 0.275, Total Score: 0.250\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.12389281309563897, Weighted Ratio: 0.300, Total Score: 0.176\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.1541652651642561, Weighted Ratio: 0.325, Total Score: 0.171\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.6065702433008174, Weighted Ratio: 0.350, Total Score: -0.257\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.7013118062563063, Weighted Ratio: 0.375, Total Score: -0.326\n",
      "Best Pruning Ratio: 0.55, Highest Score: 0.250\n",
      "\n",
      "Scores for Attn + SGFN:\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.005815885676303919, Weighted Ratio: 0.000, Total Score: 0.006\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: 0.004985044865404945, Weighted Ratio: 0.025, Total Score: 0.030\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: -0.005538938739337858, Weighted Ratio: 0.050, Total Score: 0.044\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: -0.00969314279384066, Weighted Ratio: 0.075, Total Score: 0.065\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.036695469148111635, Weighted Ratio: 0.100, Total Score: 0.063\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.04264982829289857, Weighted Ratio: 0.125, Total Score: 0.082\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.04292677522986543, Weighted Ratio: 0.150, Total Score: 0.107\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.04015730586019771, Weighted Ratio: 0.175, Total Score: 0.135\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: -0.10662457073224721, Weighted Ratio: 0.200, Total Score: 0.093\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.1095325135704004, Weighted Ratio: 0.225, Total Score: 0.115\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.12559543591447792, Weighted Ratio: 0.250, Total Score: 0.124\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: -0.21020272515785982, Weighted Ratio: 0.275, Total Score: 0.065\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.3956186994571828, Weighted Ratio: 0.300, Total Score: -0.096\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.5342306414091068, Weighted Ratio: 0.325, Total Score: -0.209\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.6563642406114979, Weighted Ratio: 0.350, Total Score: -0.306\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.6862745098039212, Weighted Ratio: 0.375, Total Score: -0.311\n",
      "Best Pruning Ratio: 0.35, Highest Score: 0.135\n",
      "\n",
      "Scores for VLSAT:\n",
      "  Pruning Ratio 0.0, Weighted Diff-Loss: 0.029480476137501453, Weighted Ratio: 0.000, Total Score: 0.029\n",
      "  Pruning Ratio 0.05, Weighted Diff-Loss: -0.03337412392924733, Weighted Ratio: 0.025, Total Score: -0.008\n",
      "  Pruning Ratio 0.1, Weighted Diff-Loss: -0.02391812214929317, Weighted Ratio: 0.050, Total Score: 0.026\n",
      "  Pruning Ratio 0.15, Weighted Diff-Loss: -0.02224941595283076, Weighted Ratio: 0.075, Total Score: 0.053\n",
      "  Pruning Ratio 0.2, Weighted Diff-Loss: -0.026143063744576645, Weighted Ratio: 0.100, Total Score: 0.074\n",
      "  Pruning Ratio 0.25, Weighted Diff-Loss: -0.03114918233396307, Weighted Ratio: 0.125, Total Score: 0.094\n",
      "  Pruning Ratio 0.3, Weighted Diff-Loss: -0.03170541773278492, Weighted Ratio: 0.150, Total Score: 0.118\n",
      "  Pruning Ratio 0.35, Weighted Diff-Loss: -0.043942596506842825, Weighted Ratio: 0.175, Total Score: 0.131\n",
      "  Pruning Ratio 0.4, Weighted Diff-Loss: -0.04171765491155778, Weighted Ratio: 0.200, Total Score: 0.158\n",
      "  Pruning Ratio 0.45, Weighted Diff-Loss: -0.03615530092335107, Weighted Ratio: 0.225, Total Score: 0.189\n",
      "  Pruning Ratio 0.5, Weighted Diff-Loss: -0.03671153632217136, Weighted Ratio: 0.250, Total Score: 0.213\n",
      "  Pruning Ratio 0.55, Weighted Diff-Loss: -0.16742685504505542, Weighted Ratio: 0.275, Total Score: 0.108\n",
      "  Pruning Ratio 0.6, Weighted Diff-Loss: -0.40549560574034965, Weighted Ratio: 0.300, Total Score: -0.105\n",
      "  Pruning Ratio 0.65, Weighted Diff-Loss: -0.4639003226165307, Weighted Ratio: 0.325, Total Score: -0.139\n",
      "  Pruning Ratio 0.7, Weighted Diff-Loss: -0.5067304483257322, Weighted Ratio: 0.350, Total Score: -0.157\n",
      "  Pruning Ratio 0.75, Weighted Diff-Loss: -0.6841695405495603, Weighted Ratio: 0.375, Total Score: -0.309\n",
      "  Pruning Ratio 0.8, Weighted Diff-Loss: -0.8666147513627767, Weighted Ratio: 0.400, Total Score: -0.467\n",
      "  Pruning Ratio 0.85, Weighted Diff-Loss: -0.9711870063410832, Weighted Ratio: 0.425, Total Score: -0.546\n",
      "  Pruning Ratio 0.9, Weighted Diff-Loss: -0.9711870063410832, Weighted Ratio: 0.450, Total Score: -0.521\n",
      "  Pruning Ratio 0.95, Weighted Diff-Loss: -0.9711870063410832, Weighted Ratio: 0.475, Total Score: -0.496\n",
      "Best Pruning Ratio: 0.5, Highest Score: 0.213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results = display_scores(models_data)\n",
    "#final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# SGFN 구조화된 및 비구조화된 프루닝 결과\n",
    "structured_data = {\n",
    "    \"Pruning Ratio\": [0.1, 0.6, 0.55, 0.25, 0.75, 0.45, 0.65, 0.9, 0.5, 0.8, 0.95, 0.85, 0.7, 0.2, 0.05, 0.4, 0.3, 0, 0.35, 0.15],\n",
    "    \"3d obj Acc@1\": [52.476, 16.860, 25.016, 51.128, 14.942, 36.965, 14.415, 4.067, 32.308, 10.074, 4.067, 4.067, 13.762, 51.992, 52.476, 41.538, 50.516, 52.476, 47.355, 52.666],\n",
    "    \"3d rel Acc@1\": [89.867, 17.495, 19.248, 87.026, 6.866, 73.036, 15.696, 5.567, 24.391, 5.575, 5.567, 5.567, 12.292, 88.793, 90.050, 81.211, 85.576, 89.968, 85.734, 89.356],\n",
    "    \"3d triplet Acc@50\": [88.248, 73.122, 73.464, 87.256, 72.359, 77.101, 72.689, 72.344, 74.835, 72.294, 72.344, 72.344, 72.444, 87.921, 88.431, 80.276, 86.597, 88.486, 84.572, 88.107]\n",
    "}\n",
    "\n",
    "unstructured_data = {\n",
    "    \"Pruning Ratio\": [0.8, 0.65, 0.85, 0.75, 0.45, 0.5, 0.35, 0.3, 0.25, 0.6, 0.05, 0.7, 0.1, 0.4, 0.9, 0.15, 0.95, 0.2, 0.55],\n",
    "    \"3d obj Acc@1\": [38.609, 49.631, 32.455, 43.267, 51.949, 51.823, 52.055, 52.308, 52.624, 50.896, 52.476, 46.575, 52.476, 51.970, 23.878, 52.497, 4.067, 52.518, 51.149],\n",
    "    \"3d rel Acc@1\": [85.145, 89.071, 79.773, 87.398, 89.807, 89.681, 89.879, 89.998, 89.986, 89.267, 89.956, 88.337, 89.946, 89.874, 53.827, 89.973, 13.326, 89.906, 89.525],\n",
    "    \"3d triplet Acc@50\": [82.103, 87.256, 77.862, 84.398, 88.417, 88.208, 88.528, 88.506, 88.491, 87.631, 88.508, 85.920, 88.516, 88.508, 73.616, 88.508, 72.639, 88.513, 87.928]\n",
    "}\n",
    "# DataFrame 생성 및 정렬\n",
    "df_structured = pd.DataFrame(structured_data).sort_values('Pruning Ratio').round(2)\n",
    "df_unstructured = pd.DataFrame(unstructured_data).sort_values('Pruning Ratio').round(2)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df_structured.to_csv('sgfn_baseline_st_results.csv', index=False)\n",
    "df_unstructured.to_csv('sgfn_baseline_unst_results.csv', index=False)\n",
    "\n",
    "print(\"CSV 파일이 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlsat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
